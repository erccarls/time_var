{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from adsy.ipython import *\n",
      "from pandas import *\n",
      "extended_styles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle, numpy as np, matplotlib.pyplot as plt\n",
      "import psf# Module for gaussian PSF convolution\n",
      "import MCSTATS\n",
      "from sklearn.ensemble import GradientBoostingClassifier\n",
      "\n",
      "# Universal Simulation Parameters\n",
      "sizeX,sizeY,sizeT = 20.,20.,24. # Define box size\n",
      "dens = 10 #dens/sq deg\n",
      "\n",
      "N_bg = dens*sizeX*sizeY # Number of background events to be distributed randomly\n",
      "r_68 = 1.0 # Spatial PSF size in degrees \n",
      "numProcs = 12 # How many CPU to use\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def AddCentralPointSource(X,Y,T,sig_on):\n",
      "    # Pick random centroid\n",
      "    cx,cy,ct = 0,0,0\n",
      "    # pick burst length \n",
      "    t_burst = 12*np.random.ranf()\n",
      "    #t_burst=6.\n",
      "    if t_burst < 1: t_burst =2.\n",
      "    \n",
      "    N_sig_on = sig_on*t_burst\n",
      "    x,y,t = np.zeros(N_sig_on), np.zeros(N_sig_on), (np.random.ranf(N_sig_on)-0.5)*t_burst\n",
      "    x,y,t = x+cx, y+cy, t+ct\n",
      "    # Shift the signal photons using the PSF\n",
      "    x,y = psf.ApplyGaussianPSF(XMASTER=x,YMASTER=y,r_68=r_68 )\n",
      "    X = np.append(X,x)\n",
      "    Y = np.append(Y,y)\n",
      "    T = np.append(T,t)\n",
      "    return X,Y,T,(cx,cy,ct,N_sig_on,t_burst)\n",
      "    \n",
      "    \n",
      "# Define a function to run the simulation given a set of input parameters\n",
      "# Optimized via numpy's vector routines\n",
      "\n",
      "def RunSim(numSources,sig_on):\n",
      "    # Generate the signal\n",
      "    src = []\n",
      "    X,Y,T = [],[],[]\n",
      "    for i in range(numSources):\n",
      "        #ret = AddRandomPointSource(X,Y,T)\n",
      "        ret = AddCentralPointSource(X,Y,T,sig_on)\n",
      "        X,Y,T,src2 = ret\n",
      "        src.append(src2)\n",
      "    idx = np.where(np.logical_and(T>-.5*sizeT,T<0.5*sizeT))\n",
      "    X= X[idx]\n",
      "    Y= Y[idx]\n",
      "    T= T[idx]\n",
      "    # Generate the background photons-Don't shift these by the PSF\n",
      "    X = np.append(X,(np.random.ranf(N_bg)-.5)*sizeX)\n",
      "    Y = np.append(Y,(np.random.ranf(N_bg)-.5)*sizeY)\n",
      "    T = np.append(T,(np.random.ranf(N_bg)-.5)*sizeT)\n",
      "    return X,Y,T,src\n",
      "\n",
      "\n",
      "def Identify_Clusters(scan,src):\n",
      "    identities = []\n",
      "    cx,cy,ct,N_sig_on,t_burst = np.transpose(src)\n",
      "    for j in range(len(scan.Members)):\n",
      "        # Compute radius in units of 3-sigma uncertainty on centroid positions\n",
      "        r  = np.sqrt(np.square(scan.CentX[j]-cx) + np.square(scan.CentY[j]-cy))/(scan.MedR[j]/2.)\n",
      "        dT = np.abs((scan.CentT[j]-ct)/(scan.Size95T[j]))\n",
      "        idx = np.where(np.logical_and(r<1,dT<1)==True)[0]\n",
      "        if np.shape(idx)[0] == 0:\n",
      "            identities.append(-1)\n",
      "        elif np.shape(idx)[0] == 1:\n",
      "            identities.append(idx[0])\n",
      "            #print \"Cluster Identified With Original Source: \", idx\n",
      "        else: \n",
      "            identities.append(idx[0])\n",
      "            #print \"Confusion Detected Defaulting to first source\"\n",
      "    return identities\n",
      "\n",
      "\n",
      "def RunAll(n_sig_on,n_min_sig):\n",
      "    # Run sims\n",
      "    mcSims, srcList = [], []\n",
      "    for i in range(numSims):\n",
      "        X,Y,T,src = RunSim(numSources,n_sig_on)\n",
      "        mcSims.append((X,Y,T))\n",
      "        srcList.append(src)\n",
      "    # DBSCAN\n",
      "    expBG     = dens*np.pi*r_68**2 * (2*a/sizeT) # expected number of events in a cylinder of height 2a\n",
      "    nMin = expBG + n_min_sig*np.sqrt(expBG)\n",
      "    scan = MCSTATS.DBSCAN_Compute_Clusters(mcSims, eps=r_68, timeScale=a, min_samples=nMin, numProcs=numProcs,sigMethod='isotropic',inner=1.25, outer=2.0,plot=False,BGDensity=dens,TotalTime = sizeT)  \n",
      "    \n",
      "\n",
      "    \n",
      "    # Identify detected clusters with the original list\n",
      "    identities = []\n",
      "    for i in range(len(scan)):\n",
      "        identities.append(Identify_Clusters(scan[i],srcList[i]))\n",
      "    \n",
      "    cnt = np.zeros(len(identities))\n",
      "    cnt10 = np.zeros(len(identities))\n",
      "    \n",
      "    for k in range(len(cnt)):\n",
      "        for i in range(numSources):\n",
      "            if i not in identities[k]:\n",
      "                if srcList[k][i][3]>20: cnt[k] +=1\n",
      "                if srcList[k][i][3]>10: cnt10[k] +=1\n",
      "    \n",
      "    detfrac = np.mean([np.count_nonzero(np.array(k)!=-1) for k in identities])\n",
      "    mean_UID = np.mean([np.count_nonzero(np.array(k)==-1) for k in identities])\n",
      "    \n",
      "    mean_UID = np.mean([np.count_nonzero(np.logical_and(np.array(identities[k])==-1,scan[k].Sigs>2.0)) for k in range(len(identities))])\n",
      "    \n",
      "    # BDT portion\n",
      "    # Make list with half sims going to training and half going to testing\n",
      "    X,Y = [[],[],[],[],[],[],[]],  [[],[],[],[],[],[],[]]\n",
      "    for i in range(len(scan)):\n",
      "        s = scan[i]\n",
      "        sample = (s.Size95X,s.Size95Y,s.Size95T,s.MedR,s.MedT, s.Members, s.Sigs)\n",
      "        for k in range(len(sample)):\n",
      "            X[k] = np.append(X[k], sample[k]) # Nsamples x NFeatures\n",
      "        Y = np.append(Y,(np.array(identities[i]) !=-1).astype(int)) # flag all identified clusters as signal and all others as background\n",
      "    \n",
      "    cut = int(np.shape(X)[1]/2.)\n",
      "    X_train,Y_train = np.transpose(np.array(X)[::,:cut]),Y[:cut] # Training samples\n",
      "    X_test,Y_test = np.transpose(np.array(X)[::,cut:]),Y[cut:]   # BG samples\n",
      "    # Load BDT algorithms\n",
      "    if np.count_nonzero(Y_train)==0 or np.count_nonzero(Y_train==0)==0:\n",
      "        return detfrac, mean_UID, detfrac, mean_UID\n",
      "    \n",
      "    clf = GradientBoostingClassifier(n_estimators=500, learning_rate=1.0,max_depth=3, random_state=0).fit(X_train, Y_train)\n",
      "    \n",
      "    BDTscore = clf.score(X_test, Y_test)\n",
      "    pred = clf.predict(X_test)\n",
      "    real  = np.where(pred==1)[0] \n",
      "    fake = np.where(pred==0)[0]\n",
      "    \n",
      "    detfracBDT = np.count_nonzero(np.logical_and(pred==1,Y_test==1))/float(numSims/2.)\n",
      "    #falsefracBDT = np.count_nonzero(np.logical_and(pred==1,Y_test==0))/float(numSims/2.)/(sizeX*sizeY)\n",
      "    \n",
      "    uid_bdt = np.logical_and(np.transpose(X_test)[6]>2. ,np.logical_and(pred==1,Y_test==0))\n",
      "    \n",
      "    falsefracBDT = np.count_nonzero(uid_bdt)/float(numSims/2.)/(sizeX*sizeY)\n",
      "    \n",
      "    \n",
      "     # returns:\n",
      "     # fraction correctly identified\n",
      "     # false/sq. deg\n",
      "     # correctly identified after BDT\n",
      "     # false after BDT\n",
      "    return detfrac, mean_UID, detfracBDT, falsefracBDT\n",
      "    \n",
      "nminsigList=[3, 4, 5, 6, 7]\n",
      "sig_on_list = range(0,26,1)\n",
      "numSims = 2000\n",
      "numSources = 1\n",
      "a = 1.\n",
      "master_stats=[]\n",
      "master_false=[]\n",
      "for nminsig in nminsigList:\n",
      "    print nminsig\n",
      "    stats = [RunAll(sig_on,nminsig) for sig_on in sig_on_list]\n",
      "    master_stats.append(np.transpose(stats))\n",
      "    master_false.append((np.mean(np.transpose(stats)[1]),np.mean(np.transpose(stats)[3])))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/carlson/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:350: RuntimeWarning: overflow encountered in exp\n",
        "  return y - 1.0 / (1.0 + np.exp(-pred.ravel()))\n",
        "/home/carlson/anaconda/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.py:868: RuntimeWarning: overflow encountered in exp\n",
        "  proba[:, 1] = 1.0 / (1.0 + np.exp(-score.ravel()))\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "4\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "6\n"
       ]
      }
     ],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(0,figsize=(12,4))\n",
      "\n",
      "col = ['b','k','m','y','r','g']\n",
      "for i in range(0,len(nminsigList),2):\n",
      "    c = col[i]\n",
      "    stats = master_stats[i]\n",
      "    plt.ylabel('Real Cluster Detection Efficiency',fontsize=12)\n",
      "    plt.subplot(121)\n",
      "    plt.plot(sig_on_list,stats[0],label=r'$N_{\\rm min,\\sigma}=$'+ str(nminsigList[i]),c=c)\n",
      "    plt.plot(sig_on_list,stats[2],c=c,ls='--')\n",
      "    plt.ylim(0,1.2)\n",
      "    plt.xlabel(r'Photons Per Month',fontsize=12)\n",
      "    \n",
      "#plt.legend(loc=4,ncol=1,bbox_to_anchor=(1.1, -.45),columnspacing= .75)\n",
      "plt.legend(loc=4,ncol=1,columnspacing= .75)\n",
      "    \n",
      "plt.subplot(122)\n",
      "plt.ylabel('False Clusters Per Square Degree',fontsize=12)\n",
      "plt.plot(nminsigList,np.transpose(master_false)[0],label=r'No BDT',c='k')\n",
      "plt.plot(nminsigList,np.transpose(master_false)[1],label=r'With BDT',c='k',ls='--')\n",
      "plt.ylim(0.0001,10)\n",
      "plt.xlabel(r'$N_{\\rm min,\\sigma}$',fontsize=16)\n",
      "plt.legend(loc=1)\n",
      "plt.yscale('log')\n",
      "plt.savefig('BDT_efficiencies.pdf')\n",
      "plt.show()\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}